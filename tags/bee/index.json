[{"content":"Sample images from Pixabay\n","description":"cartoon gallery","id":2,"section":"gallery","tags":null,"title":"Cartoon","uri":"https://junfff.github.io/gallery/cartoon/"},{"content":"Sample images from Pixabay\n","description":"photo gallery","id":3,"section":"gallery","tags":null,"title":"Photo","uri":"https://junfff.github.io/gallery/photo/"},{"content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","description":"Hugo, the world’s fastest framework for building websites","id":8,"section":"","tags":null,"title":"About","uri":"https://junfff.github.io/about/"},{"content":"Subject TestTest 12312312332121123123312321  ","description":"","id":12,"section":"posts","tags":["ArchLinux"],"title":"ArchLinux Tes9999999","uri":"https://junfff.github.io/posts/test/archlinux/2022-02-20-tst/"},{"content":"Subject 1312312312312321 TestTest\n","description":"","id":13,"section":"posts","tags":["ArchLinux"],"title":"ArchLinux Test","uri":"https://junfff.github.io/posts/test/archlinux/archlinuxtest/"},{"content":"Subject 1312312312312321 TestTest 12312312332121123123312321\n","description":"","id":14,"section":"posts","tags":["ArchLinux"],"title":"ArchLinux Test123","uri":"https://junfff.github.io/posts/test/archlinux/2022-02-19-archlinuxtest/"},{"content":"由于升级到了 gnupg-2.1，pacman 上游更新了密钥环的格式，这使得本地的主密钥无法签署其它密钥。这不会出问题，除非你想自定义 pacman 密钥环。不过，我们推荐所有用户都生成一个新的密钥环以解决潜在问题。\n此外，我们建议您安装 haveged，这是一个用来生成系统熵值的守护进程，它能加快加密软件（如 gnupg，包括生成新的密钥环）关键操作的速度。\n要完成这些操作，请以 root 权限运行：\npacman -Syu haveged\nsystemctl start haveged\nsystemctl enable haveged\nrm -fr /etc/pacman.d/gnupg\npacman-key \u0026ndash;init\npacman-key \u0026ndash;populate archlinux\npacman-key \u0026ndash;populate archlinuxcn\n","description":"","id":15,"section":"posts","tags":["ArchLinux"],"title":"ArchLinux密钥环","uri":"https://junfff.github.io/posts/test/archlinux/gnupg-2.1%E4%B8%8Epacman%E5%AF%86%E9%92%A5%E7%8E%AF/"},{"content":"Welcome Hello world, this is my first Jekyll blog post.\nI hope you like it!\n","description":"","id":16,"section":"posts","tags":["bee"],"title":"HelloWorld","uri":"https://junfff.github.io/posts/test/2020-12-08-helloworld/"},{"content":"Subject C++ 构造函数可以是虚函数吗？ 析构函数可以是虚函数吗？   1.构造函数不能为虚函数\n  当我们将构造函数定义为虚函数时,会直接报错:\n  首先回忆下以前学的virtual虚函数概念:\n  如果类定义了虚函数,创建对象时,则会分配内存空间,并且为该父类以及其所有子类的内存空间上额外分配一个虚函数表.\n  虚函数表的作用在于,存储每个类的相同的虚函数名,然后每一次虚函数调用,都会去虚函数表查找地址\n  分析:\n  假如构造函数是虚函数的话,由于对象开始还未分配内存空间,所以根本就无法找到虚函数表,从而构造函数也无法被调用.所以构造函数是不能成为虚函数.\n  2.析构函数可以为虚函数\n  首先回忆下析构函数:\n  当某个内对象被注销时,编译器会自动顺序调用该类以及其父类的析构函数,而不会调用派生类的析构函数.\n  虚析构函数的好处\n  假如我们通过派生类生成基类对象时,如果析构函数是虚函数,则我们释放其基类对象时,能使整个类(包括派生类)对象完全释放,如果析构函数只是普通函数,则不能析构完全.\n  分析:\n  所以当我们在用多态的时候(通过基类来调用派生类成员函数),析构函数最好为虚函数\n  #include \nusing namespace std;\nclass ClassBase\n{\npublic:\nClassBase(){};\nvirtual ~ClassBase()\n{\ncout\u0026laquo;\u0026quot;~ClassBase()\u0026quot;\u0026laquo;endl;\n}\nvirtual void func() //虚函数成员 { cout\u0026lt;\u0026lt;\u0026quot;ClassBase: func()\u0026quot;\u0026lt;\u0026lt;endl; }  };\nclass ClassDerived : public ClassBase\n{\npublic:\nClassDerived(){};\n~ClassDerived()\n{\ncout\u0026laquo;\u0026quot;~ClassDerived()\u0026quot;\u0026laquo;endl;\n}\nvoid func() //虚函数成员\n{\ncout\u0026laquo;\u0026ldquo;ClassDerived: func()\u0026quot;\u0026laquo;endl;\n}\n};\nint main()\n{\nClassBase *p = new ClassDerived;\n p-\u0026gt;func(); //通过多态来调用派生类虚函数 delete p; return 0;  }\n  打印如下:\n  ClassBase: func()\n  ~ClassDerived()\n  ~ClassBase()\n    ","description":"","id":17,"section":"posts","tags":["Interview"],"title":"Interview::C++虚函数-构造函数","uri":"https://junfff.github.io/posts/test/interview/2021-06-29-c++%E8%99%9A%E5%87%BD%E6%95%B0-%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"},{"content":"Subject   从2个红球，2个黄球，1个白球中随机取出两个球，则两球颜色不同的概率是___．.\n 从5个球中任意取两个共有C52=10种，两球颜色相同的有2种，两球颜色不同的概率是1-2/10=4/5，\n故答案为：4/5．\n根据互斥时间的概率公式计算即可．\n本题考点：古典概型及其概率计算公式  考点点评： 本题考查了概率的基本性质和等可能事件的概率，求解方法采用了正难则反的原则，解答的关键是求出基本事件总数和发生事件的个数，属基本题型\n  ","description":"","id":18,"section":"posts","tags":["Interview"],"title":"Interview::five-ball-select-two","uri":"https://junfff.github.io/posts/test/interview/2021-06-26-five-ball-select-two/"},{"content":"Subject  int a = 3; int b = 4; int c = 5; int x = 0; for (int i = 0; i \u0026lt; a; i++) { for (int j = 0; j \u0026lt; b; j++) { for (int k = 0; k \u0026lt; c; k++) { x++; } } } 任意断点 x 位置,根据 x 值 推断 i j k,求出公式。 x = 58 k = 58%5=3 , j = 58/5=11%4=3, i =11/4=2 x = 33 k = 33%5=3 , j = 33/5=6%4=2, i =6/4=1 公式： k=x%c,j=x/c%b, i=x/c/b  ","description":"","id":19,"section":"posts","tags":["Interview"],"title":"Interview::for-for-for","uri":"https://junfff.github.io/posts/test/interview/2021-06-26-for-for-for/"},{"content":"Subject assetBundle.Unload true 和false 区别 - 当传入的参数为true，则不仅仅内存中的AssetBundle对象包含的资源会被销毁。根据这些资源实例化而来的游戏内的对象也会销毁。 - 当传入的参数为false，则仅仅销毁内存中的AssetBundle对象包含的资源。  Unity GC 机制 战场优化 模型预加载 动态图集 光效粒子 屏幕内外 自定义UIMesh GPU Instancing, 容器扩容优化，遍历容器，线程安全容器 寻路 A* B* 物理碰撞,静态碰撞。动态碰撞RVO 动态图集的优化原理是什么 所谓动态图集就是没有办法静态生成的，需要在运行时动态生成的图集，那么我们为什么需要动态图集？ 动态图集是为了解决游戏中动态图片太多的问题，也就是我们没有办法预先放在UI上的。下图案例中可以看到右下角的英雄技能图标、天赋技能图标，以及主动使用的物品图片，均为动态加载。左上角的英雄头像也是动态加载，而且由于技能之类的图片太多（毕竟有几十个英雄），所以没有办法打成一张静态图集。而如果作为独立图片动态加载，就会多十几个DrawCall。即便是打成多张静态图集，也会导致UI渲染的批次被打断。 解决方案：用动态打图集的方式。因为我们没有Unity源码，所以图集的分块算法参考了这个开源项目 http://davikingcode.com/blog/unity-generate-spritesheets-at-runtime/，这个算法效率比较不错，建议大家可以研究一下，它的分块算法的思路上本质上类似于BSP。 大图集是在游戏Loading时获得动态图片，然后把这些动态图片渲染到RenderTexture上，用GPU的方式来做可以保证加载的效率。在游戏中，英雄头像使用了一张256x256的RenderTexture，而英雄技能、天赋技能和物品图标使用了一张512x512的RenderTexture。这样一来，技能面板动态图标的消耗从12个DrawCall降低到1个DrawCall。而英雄头像部分，从最多9个DrawCall降低到2个DrawCall，这个结果是因为敌我双方英雄头像使用的材质不同。实际操作中，技能面板的动态图片放在同一个层级里，这样就只有1个DrawCall，上面的蒙板、边框零散图片打成静态图集，在不出现穿插的情况下，UGUI也会协助合批。因此通过这种方式大量减少了DrawCall。后面讲到的一些点其实也用到了动态图集。 渲染流水线的原理 渲染流程，可以分为三个阶段。应用阶段，几何阶段，光栅化阶段 ecs 优缺点，和mvc这些相比。 为啥选ecs mvc 面向对象,（继承，多态，封装）高度耦合， 一个英雄charactor包含了 属性，状态，控制器 ecs 面向数据：（组合模式）推崇组合优于继承理念，函数式编程，system只对他关系的component负责。业务上更加专一。遍历内存上更加高效（保证内存的连续性）,业务拆分的越细 代码复用率越高 帧同步 浮点类型，多线程，随机种子，静态变量，全局变量，容器顺序需要确定性 内存和虚拟内存的区别 指的是把硬盘中的一部分空间用来当做内存使用,虚拟内存的作用：是为了解决计算机在运行较大的程序时内存不足的情况,虚拟内存是在硬盘上的，它的速度要比内存慢的多，虚拟内存其实就是为了运行很大的程序的一种妥协的办法，妥协了软件的运行速度。 子类为什么可以赋值给基类对象 基类的指针可以指向派生类对象，但是反过来则不行，派生类的指针不可以指向基类的指针。这是为什么呢？这是因为派生类的对象所占的存储空间通常要比基类的对象大，原因就是派生类除了继承基类的成员之外，还拥有自己的成员，所以基类的指针操作派生类的对象时，由于基类指针会向操作基类对象那样操作派生类对象，而基类对象所占用的内存空间通常小于派生类对象，所以基类指针不会超出派生类对象去操作数据。 同样的道理，基类的引用可以作为派生类对象的别名，但是反过来则不行，派生类的引用不可以作为基类对象的别名。 自定义的UI Mesh 构造出来的Mesh使用一个单独的正交摄像机来绘制， 在UI Mesh的构造函数中可以看到是创建了一个GameObject，附加MeshFilter和MeshRenderer，然后再做一些初始化的工作。 重点在于自行填充Mesh的三个Buffer：位置、UV和索引。另外为了避免在运行时重复申请内存，在初始化的时候要申请足够多的顶点。 在实际游戏中用到了多个UI Mesh，总体的顶点数大概在3000左右。 初始化Mesh之后，还要去维护顶点Buffer。一个小兵的血条包含背景底框和前景血条，2个矩形8个顶点，在游戏中去动态地改变这8个顶点的位置。如果某个Actor不在视野中，那么把它所有顶点坍缩到一个点就不显示了。另外，Actor死亡的时候，并不删除它的数据，而是先设置为不显示，然后缓存起来准备复用。也就是说无论整场战斗创建了多少个角色，实际上血条都是在这个Mesh的Buffer里不断复用。 ================================================================================================================================ (.net)装箱拆箱的概念  装箱是将值类型转换为 object 类型或由此值类型实现的任何接口类型的过程. CLR 对值类型进行装箱时，会将值包装在 System.Object 实例中并将其存储在托管堆中。 拆箱(取消装箱)将从对象中提取值类型。 装箱是隐式的；取消装箱是显式的。 int i =1; object o = i; //装箱 i = (int)o; //拆箱 (3D数学)4元数的做用是什么? 相比欧拉角的优点有哪些? 图形学用4元数表示旋转. 1) 解决万向节死锁问题; 2) 四元数方便插值, 求逆运算 (图形学)深度缓冲区(Depth Buffer)是什么? 有什么作用? 模板缓冲(stencil buffer)是什么, 有什么作用? 深度缓冲区（或 z 缓冲区）存储深度信息，以控制渲染哪些多边形区域。用于决定不透明物体是否被绘制. 模具缓冲区用于遮罩图像中的像素，以产生特殊效果。 掩码控制是否绘制像素。 特殊效果包括合成、贴纸、溶解、淡化、滑动、轮廓描绘和剪影, 模板缓冲区逐个像素地启用或禁用渲染目标图面绘制。 究其本质，它使应用程序遮罩部分渲染图像，因此这些部分不会显示。 应用程序常常使用模板缓冲区实现特殊效果，例如溶解、贴纸和轮廓描绘。 (图形学)纹理是什么? Unity常用的纹理类型有哪些? 常用的纹理压缩格式有哪些?(列举3种) 纹理是为图形对象(mesh)提供纹理外观的像素颜色的位图. 位图资源(jpeg, png) 加载到引擎后变为纹理资源, 纹理资源是存储纹素的数据结构, 纹素是可以读取或者写入纹理的最小单位. 在着色器读取纹理时, 可以通过采样器对纹理进行筛选和读取. 纹理有1d纹理, 2d纹理和3d纹理. 纹理经常包括若干层级的mipmap. 类型有 Default, Sprite(2D andUI), NormalMap, EditorGUI, Ligthmap, Cookie windows下有 DXT5 Android系统下常用 ETC1, ETC2, iOS 常用 PVRTC (图形学) UV坐标是什么? //todo: 待完善. uv坐标是归一化后(Normalized)的纹素坐标. ?? (图形学)MipMap是什么，作用？ MipMapping：在三维计算机图形的贴图渲染中有常用的技术，为加快渲染进度和减少图像锯齿，贴图被处理成由一系列被预先计算和优化过的图片组成的文件，这样的贴图被称为MipMap。 (C# 难度: 较高)泛型接口的抗变(也叫逆变 Contravariance)和协变(Covariance)有什么区别? 先说定义, 协变和逆变能够实现数组类型、委托类型和泛型类型参数的隐式引用转换。 在面向对象设计中子类的实例可以赋值给父类类型的变量, 这是协变. 如 object o = \u0026ldquo;hello\u0026rdquo; 是正确的, 这个是符合里氏替换原则, 但是 string s = new object(), 这样的隐式转换语法不允许的, 除非自定义了等号操作符. 但是逆变让这种隐私转换变为合法的,当然有很多前置条件, 首先必须是数组类型,泛型委托或者泛型接口. 泛型参数必须用 in 关键字修饰. 也就是说这个泛型参数只能作为方法的形参类型, 而不能是返回值. .net framework4 之后支持变体泛型接口. 委托的逆变的好处可以使用一个事件处理程序, 而不是多个单独的处理程序, 下面代码演示了委托的逆变. ?? 泛型接口的逆变的设计还有待发掘, 欢迎补充演示代码. 下面的代码演示了分配兼容性, 协变和逆变的差异 // 分配兼容性 string str = \u0026ldquo;test\u0026rdquo;; // 子类实例可以赋值给父类 object obj = str; // 协变接口, 用out关键字参数定义 public interface IEnumerable: System.Collections.IEnumerable IEnumerable strings = new List(); // IEnumable 的泛型参数类型是 object, IEnumrable 泛型参数类型是string, 下面这样的赋值 协变符合分配兼容性 IEnumerable objects = strings; // 逆变委托 // 假设有一个这样的类函数 static void SetObject(object o) { } public delegate void Action//逆变的T, 支持父类实例赋值给子类类型 Action actObject = SetObject; 给具有逆变的委托赋值一个方法实例 // 下面的操作是逆变, 父类参数object实例赋值给子类类型string // 逆变违反了分配兼容 Action actString = actObject; 当泛型参数用 out 关键字修饰, 意味着其为协变泛型接口, 这时接口的方法只能把 T 作为函数的返回值类型, 而不能作为函数的形参类型 如: //协变接口 public interface IEnumerable: System.Collections.IEnumerable { T MyFunciton(); // 正确, T是协变 // 编译错误 error CS1961: 变型无效: 类型参数“T”必须是在 // “interface1.function2(T)”上有效的 逆变式。“T”为 协变。 void MyFunciton2(T t); } 当泛型参数用 in 关键字修饰, 意味着逆变 , T只能作为方法的形参类型, 不能作为函数的返回值类型 public interface IEqualityComparer { void MyFunction(T t); //正确, T MyFunction2(); //编译错误 error CS1961: 变型无效: 类型参数“T”必须是在“interface2.function2()”上有效的 协变式。“T”为 逆变。 } 泛型接口的抗变和协变统称为变体泛型接口 以上资料参考: c#中的逆变和协变 委托中变体 泛型接口中的变体 在泛型集合的接口中使用变体 动态加载资源的方式？ 1.Resources.Load(); 2.AssetBundle ?? AssetBundle相关 在通过AssetBundle.Unload(false)卸载AssetBundle对象后，如果重新创建该对象并加载之前加载过的资源到内存时，会出现冗余，即两份相同的资源。 被脚本的静态变量引用的资源，在调用Resources.UnloadUnusedAssets时，并不会被卸载，在Profiler中能够看到其引用情况。 unity3d从唤醒到销毁有一段生命周期，请列出系统自己调用的几个重要方法？ 答：Awake \u0026mdash;\u0026gt; Start \u0026mdash;\u0026gt; Update \u0026ndash;\u0026gt; FixedUpdate \u0026ndash;\u0026gt; LateUpdate \u0026mdash;\u0026gt;OnGUI \u0026ndash;\u0026gt;Reset \u0026ndash;\u0026gt; OnDisable \u0026ndash;\u0026gt;OnDestory; 什么是协同程序？ 在主线程运行的同时开启另一段逻辑处理，来协助当前程序的执行，协程很像多线程，但是不是多线程，Unity的协程是在每帧结束之后去检测yield的条件是否满足。 LOD是什么，优缺点是什么？ LOD(Level of detail)多层次细节，是最常用的游戏优化技术。它按照模型的位置和重要程度决定物体渲染的资源分配，降低非重要物体的面数和细节度，从而获得高效率的渲染运算。缺点是增加了内存。 什么叫动态合批？跟静态合批有什么区别？ 如果动态物体共用着相同的材质，那么Unity会自动对这些物体进行批处理。动态批处理操作是自动完成的，并不需要你进行额外的操作。 区别：动态批处理一切都是自动的，不需要做任何操作，而且物体是可以移动的，但是限制很多。 静态批处理：自由度很高，限制很少，缺点可能会占用更多的内存，而且经过静态批处理后的所有物体都不可以再移动了 6大OO设计原则？ 1.开闭原则 2.单一职责原则 3.依赖倒置原则 4.接口隔离原则 5.迪米特法则 6.里氏替换原则 什么是里氏代换原则？ 里氏替换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。通俗点：就是子类对象可以赋值给基类对象，基类对象不能赋值给子类对象 你能说出几种创建型模式 抽象工厂 建造者 工厂 原型模式/克隆模式 单例模式 简述MVC、MVP、MVVM三种模式 你有了解过多少种软件的分层结构 三层架构、六边形、洋葱架构、整洁架构 在编辑场景时将GameObject设置为Static有何作用？ 设置游戏对象为Static时，这些部分被静态物体挡住而不可见时，将会剔除（或禁用）网格对象。因此，在你的场景中的所有不会动的物体都应该标记为Static。 如果你在游戏中编写一个类，不想让其他同事继承这个类，你会怎么办？ 在类声明时与函数声明时的作用sealed修饰的类为密封类，类声明时可防止其他类继承此类，在方法中声明则可防止派生类重写此方法。 如何理解委托？ 委托类似于 C++ 函数指针，但它是类型安全的。委托允许将方法作为参数进行传递。委托可用于定义回调方法。委托可以链接在一起；例如，可以对一个事件调用多个方法。方法不需要与委托签名精确匹配。 GC是什么? 为什么要有GC？ GC是垃圾收集器。程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一： System.gc() Runtime.getRuntime().gc() 死锁的必要条件？怎么克服？ 系统的资源不足，进程的推进的顺序不合适，资源分配不当，一个资源每次只能被一个进程使用，一个资源请求资源时，而此时这个资源已阻塞，对已获得资源不放，进程获得资源时，未使用完前，不能强行剥夺。 C#是否可以对内存直接进行操作？ C#是可以对内存进行直接操作的，虽然很少用到指针，但是C#是可以使用指针的，在用的时候需要在前边加unsafe,，在.net中使用了垃圾回收机制（GC）功能，它替代了程序员，不过在C#中不可以直接使用finalize方法，而是在析构函数中调用基类的finalize()方法。 TCP、UDP协议在OSI七层模型和SI七层模型和TCP/IP四层模型中分别属于哪一层的网络协议？ 都是属于传输层的网络协议。传输层提供了应用程序之间的通信。 如何实现可靠UDP？ （高级）UGUI性能优化 1.动静分离，将程序会动态设置的组件跟静态组件分离 2.文本与图片穿插编排会打断DrawCall 3.静态合并图集，降低DrawCall 4.对于复杂的场景，可以考虑动态合并图集，降低DrawCall 5.使用多个CanvasRender，例如一个界面一个CanvasRender 6.降低Mesh重建次数 7.隐藏物件可以使用Scale=0, 移动到非渲染层级，移动位置到相机外，关闭CanvasRender （高级）游戏热更新 代码热更新的具体方案: lua, ILRT 资源热更新的具体方案: AB 资源分发方案 外部玩家存在不同的版本，如何同步升级这些版本: 打包差异升级包, 版本号 （高级）游戏SDK 渠道如何打包 渠道SDK如何接入 数组和链表的区别 从逻辑结构上来看，数组必须实现定于固定的长度，不能适应数据动态增减的情况，即数组的大小一旦定义就不能改变。当数据增加是，可能超过原先定义的元素的个数；当数据减少时，造成内存浪费； 链表动态进行存储分配，可以适应数据动态地增减的情况，且可以方便地插入、删除数据项。 从内存存储的角度看；数组从栈中分配空间（用new则在堆上创建），对程序员方便快速，但是自由度小；链表从堆中分配空间，自由度大但是申请管理比较麻烦。 从访问方式类看，数组在内存中是连续的存储，因此可以利用下标索引进行访问；链表是链式存储结构，在访问元素时候只能够通过线性方式由前到后顺序的访问，所以访问效率比数组要低。 核心素质： 抗压能力、组织协调能力、学习能力、解决问题能力、主动反馈、执行力 专业能力： 完整的上线项目经历、架构/业务设计能力、工程管理（规范、文档、代码审核） ","description":"","id":20,"section":"posts","tags":["Interview"],"title":"Interview::unity","uri":"https://junfff.github.io/posts/test/interview/2021-06-29-unity/"},{"content":"Flavors:  Synchronous channels: Channel where send() can block. Limited capacity.  Mutex + Condvar + VecDeque Atomic VecDeque (atomic queue) + thread::pack + thread::Thread::notify   Asynchronous channels: Channel where send() cannot block. Unbounded.  Mutex + Condvar + VecDeque Mutex + Condvar + LinkedList AtomicLinkedList or Atomic Queue Atomic linked list, linked list of T Atomic block linked list, linked of atomic VecDeque   Rendezvous channels: Synchronous with capacity = 0. Used for thread synchronization. Oneshot channels: Any capacity. In practice, only one call to send().  ","description":"","id":21,"section":"posts","tags":["Rust"],"title":"Rust::Channels","uri":"https://junfff.github.io/posts/test/rust/2020-12-27-rust-channels/"},{"content":"Flavors:  from url: https://blog.csdn.net/s_lisheng/article/details/80593426  【Rust】轻量级I/O库mio\n让我思考一下 2018-06-06 12:53:45 4054 收藏 3\n分类专栏： Rust 文章标签： Rust mio\n版权\nmio是rust实现的一个轻量级的I/O库。其实现基本上就是对不同操作系统底层相关API的封装，抽象出统一的接口供上层使用。Linux下为epoll，Windows下为IOCP，OS X下为kqueue。\n一、关于mio\n1、重要特性\n非阻塞TCP，UDP\nI/O事件通知epoll,kqeue,IOCP实现\n运行时零分配\n平台可扩展\n2、基础用法\n其使用方法与Linux中epoll差不多，mio底层封装了epoll，使用步骤思路：\n创建Poll\n注册事件\n事件循环等待与处理事件\nmio提供可跨平台的sytem selector访问，不同平台如下表，都可调用相同的API。不同平台使用的API开销不尽相同。由于mio是基于readiness(就绪状态)的API，与Linux epoll相似，可以看到很多API在Linux上都可以一对一映射。相比之下，Windows IOCP是基于完成（completion-based）而非基于就绪的API，所以两者间会有较多桥接。 同时mio提供自身版本的TcpListener、TcpStream、UdpSocket，这些API封装了底层平台相关API，并设为非阻塞且实现Evented trait。\nOS\tSelector\nLinux\tepoll\nOS X, iOS\tkqueue\nWindows\tIOCP\nFreeBSD\tkqueue\nAndroid\tepoll\nmio实现的是一个单线程事件循环，并没有实现线程池及多线程事件循环，如果需要线程池及多线程事件循环等需要自己实现。\n二、源码分析\n先给出mio的源码目录结构，只列出了关键的部分，如下所示：\nmio代码目录结构\nmio\n|\u0026mdash;-\u0026gt;test\n|\u0026mdash;-\u0026gt;src\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;deprecated\t//事件循环代码\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;event_loop.rs\t//EventLoop的实现，内部封装了Poll\t【1】\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;handler.rs\t//供上层实现的接口\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;net\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;mod.rs\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;tcp.rs\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;udp.rs\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;sys\t//不同系统下的实现\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;mod.rs\t|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;fuchsia\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;unix\t//Linux下封装的epoll\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;mod.rs\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;epoll.rs\t【3】\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;awakener.rs\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt;windows\t//windows下封装的iocp\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;lib.rs\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;poll.rs\t//定义Poll\t【2】\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;channel.rs\t【4】\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;event_imp.rs\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;timer.rs\t【5】\n|\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt;\u0026hellip;\u0026hellip;\n对涉及不同操作系统的部分代码，以Linux操作系统为例。在Linux操作系统中，mio封装了epoll。后面会给出相应的代码。\n【1】Eventloop代码分析\n结合前面的代码示例给出相应的关键代码如下：\nEventLoop事件循环定义，可以看到里面封装了Poll，以Linux系统举例，Poll又封装了epoll。在使用Poll或Linux中epoll时，最重要的代码是epoll_wait()等待事件Event并针对每个Event进行不同的处理。这里EventLoop将epoll_create()、epoll_wait()、epoll_ctl()进行进一步的封装，将对Event的处理抽象成Handler，供上层实现具体的逻辑处理。\n// Single threaded IO event loop.\t//这里是单线程事件循环，更多的时候我们需要加线程池，以此为基础，再进行一次封装，供上层使用\npub struct EventLoop\u0026lt;H: Handler\u0026gt; {\nrun: bool,\npoll: Poll,\tevents: Events,\t//对应epoll中的epoll_event\ntimer: Timer\u0026lt;H::Timeout\u0026gt;,\nnotify_tx: channel::SyncSender\u0026lt;H::Message\u0026gt;,\nnotify_rx: channel::Receiver\u0026lt;H::Message\u0026gt;,\nconfig: Config,\n}\n抽象出接口供上层应用实现不同事件的逻辑处理。这里有点类似于回调函数，上层用户需要在此实现业务逻辑代码，实际运行时需要将函数指针传递给底层事件循环，底层事件循环运行时会调用用户传递过来的函数。在Rust中，可能描述的不是很精准，不过可以这样理解。\npub trait Handler: Sized {\ntype Timeout;\ntype Message;\n/// Invoked when the socket represented by `token` is ready to be operated /// on. `events` indicates the specific operations that are /// ready to be performed. /// This function will only be invoked a single time per socket per event /// loop tick. fn ready(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;, token: Token, events: Ready) { }\t//【1】 /// Invoked when a message has been received via the event loop's channel. fn notify(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;, msg: Self::Message) { }\t//【2】 /// Invoked when a timeout has completed. fn timeout(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;, timeout: Self::Timeout) { }\t//【3】 /// Invoked when `EventLoop` has been interrupted by a signal interrupt. fn interrupted(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;) { }\t//【4】 /// Invoked at the end of an event loop tick. fn tick(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;) { }\t//【5】  }\n这里把Poll进行了封装，主要实现了Eventloop::new()\u0026mdash;-\u0026gt;Poll::new()\u0026mdash;-\u0026gt;epoll_create()，Eventloop::run()—\u0026gt;Selecter::select()\u0026mdash;-\u0026gt;epoll_wait()，还有register()、reregister()、deregister()等等…\nimpl\u0026lt;H: Handler\u0026gt; EventLoop {\n/// Constructs a new EventLoop using the default configuration values.\n/// The EventLoop will not be running.\npub fn new() -\u0026gt; io::Result\u0026lt;EventLoop\u0026gt; {\nEventLoop::configured(Config::default())\n}\nfn configured(config: Config) -\u0026gt; io::Result\u0026lt;EventLoop\u0026lt;H\u0026gt;\u0026gt; { // Create the IO poller let poll = Poll::new()?;\t//Linux内部调用epoll_create() let timer = timer::Builder::default() .tick_duration(config.timer_tick) .num_slots(config.timer_wheel_size) .capacity(config.timer_capacity) .build(); // Create cross thread notification queue let (tx, rx) = channel::sync_channel(config.notify_capacity); //这里创建的是同步管道,可配置同步管道内部的buffer queue bound size. // Register the notification wakeup FD with the IO poller poll.register(\u0026amp;rx, NOTIFY, Ready::readable(), PollOpt::edge() | PollOpt::oneshot())?;\t//NOTIFY和TIMER由mio实现 poll.register(\u0026amp;timer, TIMER, Ready::readable(), PollOpt::edge())?; Ok(EventLoop { run: true, poll: poll, timer: timer, notify_tx: tx, notify_rx: rx, config: config, events: Events::with_capacity(1024), }) } /// Keep spinning the event loop indefinitely, and notify the handler whenever /// any of the registered handles are ready. pub fn run(\u0026amp;mut self, handler: \u0026amp;mut H) -\u0026gt; io::Result\u0026lt;()\u0026gt; { self.run = true; while self.run { // Execute ticks as long as the event loop is running self.run_once(handler, None)?;\t//Linux下调用epoll_wait() } Ok(()) } pub fn run_once(\u0026amp;mut self, handler: \u0026amp;mut H, timeout: Option\u0026lt;Duration\u0026gt;) -\u0026gt; io::Result\u0026lt;()\u0026gt; { trace!(\u0026quot;event loop tick\u0026quot;); // Check the registered IO handles for any new events. Each poll // is for one second, so a shutdown request can last as long as // one second before it takes effect. let events = match self.io_poll(timeout) { Ok(e) =\u0026gt; e, Err(err) =\u0026gt; { if err.kind() == io::ErrorKind::Interrupted { handler.interrupted(self);\t//调用Handler::interrupted() 【4】 0 } else { return Err(err); } } }; self.io_process(handler, events);\t//处理就绪的事件，handler为如何处理各种事件的实例 handler.tick(self);\t//一轮事件处理后，最后调用Handler::tick()\t调用【5】 Ok(()) } #[inline] fn io_poll(\u0026amp;mut self, timeout: Option\u0026lt;Duration\u0026gt;) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { self.poll.poll(\u0026amp;mut self.events, timeout) } // Process IO events that have been previously polled fn io_process(\u0026amp;mut self, handler: \u0026amp;mut H, cnt: usize) { let mut i = 0; trace!(\u0026quot;io_process(..); cnt={}; len={}\u0026quot;, cnt, self.events.len()); // Iterate over the notifications. Each event provides the token // it was registered with (which usually represents, at least, the // handle that the event is about) as well as information about // what kind of event occurred (readable, writable, signal, etc.) while i \u0026lt; cnt {\t//遍历所有就绪的事件，进行处理 let evt = self.events.get(i).unwrap(); trace!(\u0026quot;event={:?}; idx={:?}\u0026quot;, evt, i); // mio在epoll之上，增加了NOTIFY和TIMER match evt.token() { NOTIFY =\u0026gt; self.notify(handler),\t//channel处理 ，这个epoll中是没有的，mio实现 TIMER =\u0026gt; self.timer_process(handler),\t//Timer处理， 这个epoll中也是没有的，mio实现 _ =\u0026gt; self.io_event(handler, evt)\t//IO事件的处理， 这个epoll有 } i += 1; } } fn io_event(\u0026amp;mut self, handler: \u0026amp;mut H, evt: Event) { handler.ready(self, evt.token(), evt.readiness());\t//调用Handler::ready() 【1】 } fn notify(\u0026amp;mut self, handler: \u0026amp;mut H) { for _ in 0..self.config.messages_per_tick { match self.notify_rx.try_recv() {\t//从channel中接收数据，内部实现是std::sync::mpsc::sync_channel() Ok(msg) =\u0026gt; handler.notify(self, msg),\t//调用Handler::notify()\t【2】 _ =\u0026gt; break, } } // Re-register let _ = self.poll.reregister(\u0026amp;self.notify_rx, NOTIFY, Ready::readable(), PollOpt::edge() | PollOpt::oneshot());\t//PollOpt::oneshot(),必须重新reregister. } fn timer_process(\u0026amp;mut self, handler: \u0026amp;mut H) { while let Some(t) = self.timer.poll() { handler.timeout(self, t);\t//调用Handler::timeout() 【3】 } } /// Registers an IO handle with the event loop. pub fn register\u0026lt;E: ?Sized\u0026gt;(\u0026amp;mut self, io: \u0026amp;E, token: Token, interest: Ready, opt: PollOpt) -\u0026gt; io::Result\u0026lt;()\u0026gt; where E: Evented { self.poll.register(io, token, interest, opt) } /// Re-Registers an IO handle with the event loop. pub fn reregister\u0026lt;E: ?Sized\u0026gt;(\u0026amp;mut self, io: \u0026amp;E, token: Token, interest: Ready, opt: PollOpt) -\u0026gt; io::Result\u0026lt;()\u0026gt; where E: Evented { self.poll.reregister(io, token, interest, opt) } /// Deregisters an IO handle with the event loop. pub fn deregister\u0026lt;E: ?Sized\u0026gt;(\u0026amp;mut self, io: \u0026amp;E) -\u0026gt; io::Result\u0026lt;()\u0026gt; where E: Evented { self.poll.deregister(io) } /// Returns a sender that allows sending messages to the event loop in a /// thread-safe way, waking up the event loop if needed. pub fn channel(\u0026amp;self) -\u0026gt; Sender\u0026lt;H::Message\u0026gt; { Sender::new(self.notify_tx.clone()) } /// Schedules a timeout after the requested time interval. When the /// duration has been reached, pub fn timeout(\u0026amp;mut self, token: H::Timeout, delay: Duration) -\u0026gt; timer::Result\u0026lt;Timeout\u0026gt; { self.timer.set_timeout(delay, token) } /// If the supplied timeout has not been triggered, cancel it such that it /// will not be triggered in the future. pub fn clear_timeout(\u0026amp;mut self, timeout: \u0026amp;Timeout) -\u0026gt; bool { self.timer.cancel_timeout(\u0026amp;timeout).is_some() } /// Tells the event loop to exit after it is done handling all events in the current iteration. pub fn shutdown(\u0026amp;mut self) { self.run = false; } /// Indicates whether the event loop is currently running. If it's not it has either /// stopped or is scheduled to stop on the next tick. pub fn is_running(\u0026amp;self) -\u0026gt; bool { self.run }  }\n【2】Poll代码分析\nPoll屏蔽了不同系统的实现，给出了统一的抽象。Poll的实现代码这里只能列出较为重要的部分代码，有一部分代码省略掉了，详细代码可查看mio/src/poll.rs：\npub struct Poll {\n// Platform specific IO selector\nselector: sys::Selector,\n// Custom readiness queue // The second readiness queue is implemented in user space by `ReadinessQueue`. It provides a way to implement purely user space `Evented` types. readiness_queue: ReadinessQueue,\t//区别于系统就绪队列（sys::Selector），这是上层自己实现的就绪队列 // Use an atomic to first check if a full lock will be required. This is a // fast-path check for single threaded cases avoiding the extra syscall lock_state: AtomicUsize, // Sequences concurrent calls to `Poll::poll` lock: Mutex\u0026lt;()\u0026gt;, // Wakeup the next waiter condvar: Condvar,  }\nimpl Poll {\n/// Return a new Poll handle.\npub fn new() -\u0026gt; io::Result {\nis_send::();\nis_sync::();\n let poll = Poll { selector: sys::Selector::new()?, readiness_queue: ReadinessQueue::new()?, lock_state: AtomicUsize::new(0), lock: Mutex::new(()), condvar: Condvar::new(), }; // Register the notification wakeup FD with the IO poller poll.readiness_queue.inner.awakener.register(\u0026amp;poll, AWAKEN, Ready::readable(), PollOpt::edge())?; Ok(poll) } /// Wait for readiness events /// /// Blocks the current thread and waits for readiness events for any of the /// `Evented` handles that have been registered with this `Poll` instance. /// The function will block until either at least one readiness event has /// been received or `timeout` has elapsed. A `timeout` of `None` means that /// `poll` will block until a readiness event has been received. pub fn poll(\u0026amp;self, events: \u0026amp;mut Events, timeout: Option\u0026lt;Duration\u0026gt;) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { self.poll1(events, timeout, false)\t//Poll::poll()非常最重要的一个方法， poll()--\u0026gt;poll1()--\u0026gt;poll2() } fn poll1(\u0026amp;self, events: \u0026amp;mut Events, mut timeout: Option\u0026lt;Duration\u0026gt;, interruptible: bool) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { let zero = Some(Duration::from_millis(0)); let mut curr = self.lock_state.compare_and_swap(0, 1, SeqCst); if 0 != curr { ... }\t//{ ... }代表中间有很多代码被省略掉了. let ret = self.poll2(events, timeout, interruptible); // Release the lock if 1 != self.lock_state.fetch_and(!1, Release) { ... }\t//{ ... }代表中间有很多代码被省略掉了. ret } #[inline] fn poll2(\u0026amp;self, events: \u0026amp;mut Events, mut timeout: Option\u0026lt;Duration\u0026gt;, interruptible: bool) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { // Compute the timeout value passed to the system selector. If the // readiness queue has pending nodes, we still want to poll the system // selector for new events, but we don't want to block the thread to // wait for new events. if timeout == Some(Duration::from_millis(0)) { // If blocking is not requested, then there is no need to prepare // the queue for sleep // // The sleep_marker should be removed by readiness_queue.poll(). } else if self.readiness_queue.prepare_for_sleep() { // The readiness queue is empty. The call to `prepare_for_sleep` // inserts `sleep_marker` into the queue. This signals to any // threads setting readiness that the `Poll::poll` is going to // sleep, so the awakener should be used. } else { // The readiness queue is not empty, so do not block the thread. timeout = Some(Duration::from_millis(0)); } //poll系统就绪队列 loop { let now = Instant::now(); // First get selector events let res = self.selector.select(\u0026amp;mut events.inner, AWAKEN, timeout);\t//Linux下调用epoll_wait(),就绪事件放入events中 match res { Ok(true) =\u0026gt; { // Some awakeners require reading from a FD. self.readiness_queue.inner.awakener.cleanup(); break; } Ok(false) =\u0026gt; break, Err(ref e) if e.kind() == io::ErrorKind::Interrupted \u0026amp;\u0026amp; !interruptible =\u0026gt; { // Interrupted by a signal; update timeout if necessary and retry if let Some(to) = timeout { let elapsed = now.elapsed(); if elapsed \u0026gt;= to { break; } else { timeout = Some(to - elapsed); } } } Err(e) =\u0026gt; return Err(e), } } // Poll custom event queue self.readiness_queue.poll(\u0026amp;mut events.inner);\t//Poll用户就绪队列 // Return number of polled events Ok(events.inner.len()) } /// Register an `Evented` handle with the `Poll` instance. pub fn register\u0026lt;E: ?Sized\u0026gt;(\u0026amp;self, handle: \u0026amp;E, token: Token, interest: Ready, opts: PollOpt) -\u0026gt; io::Result\u0026lt;()\u0026gt; where E: Evented { validate_args(token)?; // Register interests for this socket handle.register(self, token, interest, opts)?; Ok(()) } /// Re-register an `Evented` handle with the `Poll` instance. pub fn reregister\u0026lt;E: ?Sized\u0026gt;(\u0026amp;self, handle: \u0026amp;E, token: Token, interest: Ready, opts: PollOpt) -\u0026gt; io::Result\u0026lt;()\u0026gt; where E: Evented { validate_args(token)?; // Register interests for this socket handle.reregister(self, token, interest, opts)?; Ok(()) } /// Deregister an `Evented` handle with the `Poll` instance. pub fn deregister\u0026lt;E: ?Sized\u0026gt;(\u0026amp;self, handle: \u0026amp;E) -\u0026gt; io::Result\u0026lt;()\u0026gt; where E: Evented { // Deregister interests for this socket handle.deregister(self)?; Ok(()) }  }\n【3】Selector代码分析\n下面这段代码出自mio/src/sys/unix/epoll.rs是对底层Linux系统epoll的封装抽象，可以看到Selector::new()内部实际上调用了epoll_create()，Selector::select()内部实际上调用了epoll_wait()，register()、reregister()、deregister()实内部实际上调用了epoll_ctl()。如果你非常熟悉epoll，就会感觉下面的代码很熟悉，详细代码如下：\npub struct Selector {\nid: usize,\nepfd: RawFd,\n}\nimpl Selector {\npub fn new() -\u0026gt; io::Result {\nlet epfd = unsafe {\n// Emulate epoll_create by using epoll_create1 if it\u0026rsquo;s available\n// and otherwise falling back to epoll_create followed by a call to\n// set the CLOEXEC flag.\ndlsym!(fn epoll_create1(c_int) -\u0026gt; c_int);\n match epoll_create1.get() { Some(epoll_create1_fn) =\u0026gt; { cvt(epoll_create1_fn(libc::EPOLL_CLOEXEC))? } None =\u0026gt; { let fd = cvt(libc::epoll_create(1024))?; drop(set_cloexec(fd)); fd } } }; // offset by 1 to avoid choosing 0 as the id of a selector let id = NEXT_ID.fetch_add(1, Ordering::Relaxed) + 1; Ok(Selector { id: id, epfd: epfd, }) } pub fn id(\u0026amp;self) -\u0026gt; usize { self.id } /// Wait for events from the OS pub fn select(\u0026amp;self, evts: \u0026amp;mut Events, awakener: Token, timeout: Option\u0026lt;Duration\u0026gt;) -\u0026gt; io::Result\u0026lt;bool\u0026gt; { let timeout_ms = timeout .map(|to| cmp::min(millis(to), i32::MAX as u64) as i32) .unwrap_or(-1); // Wait for epoll events for at most timeout_ms milliseconds evts.clear(); unsafe { let cnt = cvt(libc::epoll_wait(self.epfd, evts.events.as_mut_ptr(), evts.events.capacity() as i32, timeout_ms))?; let cnt = cnt as usize; evts.events.set_len(cnt); for i in 0..cnt { if evts.events[i].u64 as usize == awakener.into() { evts.events.remove(i); return Ok(true); } } } Ok(false) } /// Register event interests for the given IO handle with the OS pub fn register(\u0026amp;self, fd: RawFd, token: Token, interests: Ready, opts: PollOpt) -\u0026gt; io::Result\u0026lt;()\u0026gt; { let mut info = libc::epoll_event { events: ioevent_to_epoll(interests, opts), u64: usize::from(token) as u64 }; unsafe { cvt(libc::epoll_ctl(self.epfd, libc::EPOLL_CTL_ADD, fd, \u0026amp;mut info))?; Ok(()) } } /// Register event interests for the given IO handle with the OS pub fn reregister(\u0026amp;self, fd: RawFd, token: Token, interests: Ready, opts: PollOpt) -\u0026gt; io::Result\u0026lt;()\u0026gt; { let mut info = libc::epoll_event { events: ioevent_to_epoll(interests, opts), u64: usize::from(token) as u64 }; unsafe { cvt(libc::epoll_ctl(self.epfd, libc::EPOLL_CTL_MOD, fd, \u0026amp;mut info))?; Ok(()) } } /// Deregister event interests for the given IO handle with the OS pub fn deregister(\u0026amp;self, fd: RawFd) -\u0026gt; io::Result\u0026lt;()\u0026gt; { // The \u0026amp;info argument should be ignored by the system, // but linux \u0026lt; 2.6.9 required it to be not null. // For compatibility, we provide a dummy EpollEvent. let mut info = libc::epoll_event { events: 0, u64: 0, }; unsafe { cvt(libc::epoll_ctl(self.epfd, libc::EPOLL_CTL_DEL, fd, \u0026amp;mut info))?; Ok(()) } }  }\n【4】Notify channel代码分析\n这个涉及的代码比较多，比较杂，也较为难以理解。\n// ReadinessQueue is backed by a MPSC queue that supports reuse of linked\n// list nodes. This significantly reduces the number of required allocations.\n// Each Registration / SetReadiness pair allocates a single readiness node\n// that is used for the lifetime of the registration.\n//\n// The readiness node also includes a single atomic variable, state that\n// tracks most of the state associated with the registration. This includes the\n// current readiness, interest, poll options, and internal state. When the node\n// state is mutated, it is queued in the MPSC channel. A call to\n// ReadinessQueue::poll will dequeue and process nodes. The node state can\n// still be mutated while it is queued in the channel for processing.\n// Intermediate state values do not matter as long as the final state is\n// included in the call to poll. This is the eventually consistent nature of\n// the readiness queue.\n//\n// The readiness node is ref counted using the ref_count field. On creation,\n// the ref_count is initialized to 3: one Registration handle, one\n// SetReadiness handle, and one for the readiness queue. Since the readiness queue\n// doesn\u0026rsquo;t always hold a handle to the node, we don\u0026rsquo;t use the Arc type for\n// managing ref counts (this is to avoid constantly incrementing and\n// decrementing the ref count when pushing \u0026amp; popping from the queue). When the\n// Registration handle is dropped, the dropped flag is set on the node, then\n// the node is pushed into the registration queue. When Poll::poll pops the\n// node, it sees the drop flag is set, and decrements it\u0026rsquo;s ref count.\n//\n// The MPSC queue is a modified version of the intrusive MPSC node based queue\n// described by 1024cores [1].\n#[derive(Clone)]\nstruct ReadinessQueue {\ninner: Arc,\n}\nstruct ReadinessQueueInner {\n// Used to wake up Poll when readiness is set in another thread.\nawakener: sys::Awakener,\n// Head of the MPSC queue used to signal readiness to `Poll::poll`. head_readiness: AtomicPtr\u0026lt;ReadinessNode\u0026gt;, // Tail of the readiness queue. // // Only accessed by Poll::poll. Coordination will be handled by the poll fn tail_readiness: UnsafeCell\u0026lt;*mut ReadinessNode\u0026gt;, // Fake readiness node used to punctuate the end of the readiness queue. // Before attempting to read from the queue, this node is inserted in order // to partition the queue between nodes that are \u0026quot;owned\u0026quot; by the dequeue end // and nodes that will be pushed on by producers. end_marker: Box\u0026lt;ReadinessNode\u0026gt;, // Similar to `end_marker`, but this node signals to producers that `Poll` // has gone to sleep and must be woken up. sleep_marker: Box\u0026lt;ReadinessNode\u0026gt;, // Similar to `end_marker`, but the node signals that the queue is closed. // This happens when `ReadyQueue` is dropped and signals to producers that // the nodes should no longer be pushed into the queue. closed_marker: Box\u0026lt;ReadinessNode\u0026gt;,  }\n/// Node shared by a Registration / SetReadiness pair as well as the node\n/// queued into the MPSC channel.\nstruct ReadinessNode {\n// Node state, see struct docs for ReadinessState\n//\n// This variable is the primary point of coordination between all the\n// various threads concurrently accessing the node.\nstate: AtomicState,\n// The registration token cannot fit into the `state` variable, so it is // broken out here. In order to atomically update both the state and token // we have to jump through a few hoops. // // First, `state` includes `token_read_pos` and `token_write_pos`. These can // either be 0, 1, or 2 which represent a token slot. `token_write_pos` is // the token slot that contains the most up to date registration token. // `token_read_pos` is the token slot that `poll` is currently reading from. // // When a call to `update` includes a different token than the one currently // associated with the registration (token_write_pos), first an unused token // slot is found. The unused slot is the one not represented by // `token_read_pos` OR `token_write_pos`. The new token is written to this // slot, then `state` is updated with the new `token_write_pos` value. This // requires that there is only a *single* concurrent call to `update`. // // When `poll` reads a node state, it checks that `token_read_pos` matches // `token_write_pos`. If they do not match, then it atomically updates // `state` such that `token_read_pos` is set to `token_write_pos`. It will // then read the token at the newly updated `token_read_pos`. token_0: UnsafeCell\u0026lt;Token\u0026gt;, token_1: UnsafeCell\u0026lt;Token\u0026gt;, token_2: UnsafeCell\u0026lt;Token\u0026gt;, // Used when the node is queued in the readiness linked list. Accessing // this field requires winning the \u0026quot;queue\u0026quot; lock next_readiness: AtomicPtr\u0026lt;ReadinessNode\u0026gt;, // Ensures that there is only one concurrent call to `update`. // // Each call to `update` will attempt to swap `update_lock` from `false` to // `true`. If the CAS succeeds, the thread has obtained the update lock. If // the CAS fails, then the `update` call returns immediately and the update // is discarded. update_lock: AtomicBool, // Pointer to Arc\u0026lt;ReadinessQueueInner\u0026gt; readiness_queue: AtomicPtr\u0026lt;()\u0026gt;, // Tracks the number of `ReadyRef` pointers ref_count: AtomicUsize,  }\n/// Handle to a user space Poll registration.\n///\n/// Registration allows implementing [Evented] for types that cannot work\n/// with the [system selector]. A Registration is always paired with a\n/// SetReadiness, which allows updating the registration\u0026rsquo;s readiness state.\n/// When [set_readiness] is called and the Registration is associated with a\n/// [Poll] instance, a readiness event will be created and eventually returned\n/// by [poll].\npub struct Registration {\ninner: RegistrationInner,\n}\n/// Updates the readiness state of the associated Registration.\n#[derive(Clone)]\npub struct SetReadiness {\ninner: RegistrationInner,\n}\n未完，待续…\n参考文档：Intrusive MPSC node-based queue\n【5】Timer定时器代码分析\npub struct Timer {\n// Size of each tick in milliseconds\ntick_ms: u64,\n// Slab of timeout entries\nentries: Slab\u0026lt;Entry\u0026gt;,\n// Timeout wheel. Each tick, the timer will look at the next slot for\n// timeouts that match the current tick.\nwheel: Vec,\n// Tick 0\u0026rsquo;s time instant\nstart: Instant,\n// The current tick\ntick: Tick,\n// The next entry to possibly timeout\nnext: Token,\n// Masks the target tick to get the slot\nmask: u64,\n// Set on registration with Poll\ninner: LazyCell,\n}\n未完，待续…\n三、mio用法示例\n下面的2个示例都很简单，其实直接看mio的测试代码mio/test/就好了，不用看下面的2个示例。\n1、代码示例1\n直接使用Poll示例如下：\n#[macro_use]\nextern crate log;\nextern crate simple_logger;\nextern crate mio;\nuse mio::*;\nuse mio::tcp::{TcpListener, TcpStream};\nuse std::io::{Read,Write};\nfn main() {\nsimple_logger::init().unwrap();\n// Setup some tokens to allow us to identify which event is for which socket. const SERVER: Token = Token(0); const CLIENT: Token = Token(1); let addr = \u0026quot;127.0.0.1:12345\u0026quot;.parse().unwrap(); // Setup the server socket let server = TcpListener::bind(\u0026amp;addr).unwrap(); // Create a poll instance let poll = Poll::new().unwrap(); // Start listening for incoming connections poll.register(\u0026amp;server, SERVER, Ready::readable(), PollOpt::edge()).unwrap(); // Setup the client socket let sock = TcpStream::connect(\u0026amp;addr).unwrap(); // Register the socket poll.register(\u0026amp;sock, CLIENT, Ready::readable(), PollOpt::edge()).unwrap(); // Create storage for events let mut events = Events::with_capacity(1024); loop { poll.poll(\u0026amp;mut events, None).unwrap(); for event in events.iter() { match event.token() { SERVER =\u0026gt; { // Accept and drop the socket immediately, this will close // the socket and notify the client of the EOF. let (stream,addr) = server.accept().unwrap(); info!(\u0026quot;Listener accept {:?}\u0026quot;,addr); }, CLIENT =\u0026gt; { // The server just shuts down the socket, let's just exit // from our event loop. info!(\u0026quot;client response.\u0026quot;); return; }, _ =\u0026gt; unreachable!(), } } }  }\n通过上面的代码示例1，我们可以看到其用法与epoll非常相似。\n2、代码示例2\n上面的代码编程时较为麻烦，下面使用事件循环EventLoop的方式，代码能看起来更清晰一些（相对的）：\n#[macro_use]\nextern crate log;\nextern crate simple_logger;\nextern crate mio;\nuse mio::*;\nuse mio:⏲:{Timeout};\nuse mio::deprecated::{EventLoop, Handler, Sender, EventLoopBuilder};\nuse std::thread;\nuse std::time::Duration;\nfn main() {\nsimple_logger::init().unwrap();\nlet mut event_loop=EventLoop::new().unwrap(); let channel_sender=event_loop.channel(); thread::spawn(move ||{ channel_sender.send(IoMessage::Notify); thread::sleep_ms(5*1000); channel_sender.send(IoMessage::End); }); let timeout = event_loop.timeout(Token(123), Duration::from_millis(3000)).unwrap(); let mut handler=MioHandler::new(); let _ = event_loop.run(\u0026amp;mut handler).unwrap();  }\npub enum IoMessage{\nNotify,\nEnd,\n}\npub struct MioHandler{\n}\nimpl MioHandler{\npub fn new()-\u0026gt;Self{\nMioHandler{}\n}\n}\nimpl Handler for MioHandler {\ntype Timeout = Token;\ntype Message = IoMessage;\n/// Invoked when the socket represented by `token` is ready to be operated on. fn ready(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;, token: Token, events: Ready) { } /// Invoked when a message has been received via the event loop's channel. fn notify(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;, msg: Self::Message) { match msg { IoMessage::Notify=\u0026gt;info!(\u0026quot;channel notify\u0026quot;), IoMessage::End=\u0026gt;{ info!(\u0026quot;shutdown eventloop.\u0026quot;); event_loop.shutdown(); } } } /// Invoked when a timeout has completed. fn timeout(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;, timeout: Self::Timeout) { match timeout{ Token(123)=\u0026gt;info!(\u0026quot;time out.\u0026quot;), Token(_)=\u0026gt;{}, } } /// Invoked when `EventLoop` has been interrupted by a signal interrupt. fn interrupted(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;) { } /// Invoked at the end of an event loop tick. fn tick(\u0026amp;mut self, event_loop: \u0026amp;mut EventLoop\u0026lt;Self\u0026gt;) { }  }\n这个示例说明了超时及channel，围绕EventLoop编程，其实与上一个例子没有什么不同，只是EventLoop对Poll做了封装。\n参考文档：\n【譯】Tokio 內部機制：從頭理解 Rust 非同步 I/O 框架\n使用mio开发web framework - base\nMy Basic Understanding of mio and Asynchronous IO\nMIO for Rust\nmio-github\n","description":"","id":22,"section":"posts","tags":["Rust"],"title":"Rust::mio","uri":"https://junfff.github.io/posts/test/rust/2021-02-23-rust-mio-epoll/"},{"content":"GC的实现 实现GC的策略有很多种，其中最常见一种就是 Tracing garbage collection，或者叫 Mark-Sweep，这种算法会通过一个 root Object，遍历这个该对象引用的变量，并且标记，递归这个过程，这样就确定了所有reachable的对象，剩下的对象即视为garbage。  另一种常见的策略还有引用计数（Reference counting），它是通过为每个对象维护一个引用计数，这代表当前对该对象的引用数目，当引用为0，即代表该对象为 Garage。引用技术有如下缺点  循环引用问题 保存计数带来的空间开销 修改引用数目带来的速度开销以及原子性要求 非实时（一个引用的变化可能递归得导致一系列引用修改，内存释放) 有很多算法可以一定程度解决上述问题，顺便一提，C++使用的智能指针即是基于引用计数实现的，COM对象也使用了引用计数来管理。 Unity 中的GC Unity的脚本后端是基于Mono的实现（当然现在多了个IL2CPP，不过也是类似的GC实现)，而Mono使用的GC是所谓的Boehm–Demers–Weiser garbage collector。是Mark-Sweep 的实现，它会在需要进行GC时占用主线程，进行遍历-标记-垃圾回收的过程，然后在归还主线程控制权。这会导致帧数的突然下降，产生卡顿（不过因为该实现是非压缩式的，所以卡顿现象相对较轻，但是对内存利用率进一步下降了，会有内存碎片的问题。。囧）。所以我们需要慎重地处理对象的创建（内存请求），还有释放（使用GC管理内存是没有主动释放内存的接口的，但是我们可以通过消除对某个对象的引用来做到这一点）。此外，Unity的代码分为两部分：托管与非托管，GC影响的只有托管部分的代码使用的堆内存。而且这个托管堆占用的地址空间不会返还给操作系统。。 ","description":"","id":23,"section":"posts","tags":["Unity"],"title":"Unity::GC的实现","uri":"https://junfff.github.io/posts/test/interview/2022-05-04-unity-gc/"},{"content":"{{ page.title }} 我的第一篇文章\n{{ page.date | date_to_string }}\n","description":"","id":24,"section":"posts","tags":["bee"],"title":"你好，世界","uri":"https://junfff.github.io/posts/test/2020-12-08-helloworld2/"}]